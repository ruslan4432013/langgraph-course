"""
–ü—Ä–∏–º–µ—Ä 9: –ü–æ–ª–Ω—ã–π —Ä–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å
–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç: –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª - –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è, –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ, –ø–æ–∏—Å–∫, —É–¥–∞–ª–µ–Ω–∏–µ
"""

from langchain_core.vectorstores import InMemoryVectorStore
from langchain_core.documents import Document
from langchain_core.embeddings import DeterministicFakeEmbedding

print("=" * 70)
print("–ü–û–õ–ù–´–ô –†–ê–ë–û–ß–ò–ô –ü–†–û–¶–ï–°–° –í–ï–ö–¢–û–†–ù–û–ì–û –•–†–ê–ù–ò–õ–ò–©–ê")
print("=" * 70)

# –®–ê–ì–ò 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
print("\n[–®–ê–ì 1] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞")
print("‚îÄ" * 70)
embeddings = DeterministicFakeEmbedding(size=4096)
vector_store = InMemoryVectorStore(embedding=embeddings)
print("‚úì –•—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ–∑–¥–∞–Ω–æ")

# –®–ê–ì 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
print("\n[–®–ê–ì 2] –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
print("‚îÄ" * 70)
documents = [
    Document(
        page_content="–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.",
        metadata={"category": "ML", "source": "article"},
    ),
    Document(
        page_content="–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –∏–º–∏—Ç–∏—Ä—É—é—Ç —Ä–∞–±–æ—Ç—É –º–æ–∑–≥–∞.",
        metadata={"category": "DL", "source": "article"},
    ),
    Document(
        page_content="–ì–ª—É–±–æ–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ ‚Äî –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.",
        metadata={"category": "DL", "source": "research"},
    ),
    Document(
        page_content="–†–µ—Ü–µ–ø—Ç –ø–∏—Ü—Ü—ã —Ç—Ä–µ–±—É–µ—Ç –º—É–∫—É, –ø–æ–º–∏–¥–æ—Ä—ã –∏ —Å—ã—Ä.",
        metadata={"category": "cooking", "source": "recipe"},
    ),
]
print(f"‚úì –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

# –®–ê–ì 3: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
print("\n[–®–ê–ì 3] –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ")
print("‚îÄ" * 70)
doc_ids = [f"doc{i+1}" for i in range(len(documents))]
vector_store.add_documents(documents=documents, ids=doc_ids)
print(f"‚úì –î–æ–∫—É–º–µ–Ω—Ç—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã —Å ID: {doc_ids}")

# –®–ê–ì 4: –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞
print("\n[–®–ê–ì 4] –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É")
print("‚îÄ" * 70)
queries = [
    "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?",
    "–ö–∞–∫ –≥–æ—Ç–æ–≤–∏—Ç—å –µ–¥—É?",
]

for query in queries:
    results = vector_store.similarity_search(query, k=2)
    print(f"\nüîç –ó–∞–ø—Ä–æ—Å: '{query}'")
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã (k=2):")
    for i, doc in enumerate(results, 1):
        print(f"  {i}. {doc.page_content[:50]}...")
        print(f"     –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {doc.metadata['category']}")

# –®–ê–ì 5: –£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
print("\n\n[–®–ê–ì 5] –£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞")
print("‚îÄ" * 70)
vector_store.delete(ids=["doc4"])
print("‚úì –î–æ–∫—É–º–µ–Ω—Ç 'doc4' (—Ä–µ—Ü–µ–ø—Ç –ø–∏—Ü—Ü—ã) —É–¥–∞–ª–µ–Ω")

# –®–ê–ì 6: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
print("\n[–®–ê–ì 6] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è")
print("‚îÄ" * 70)
query = "–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –æ–±—É—á–µ–Ω–∏–µ"
results = vector_store.similarity_search(query, k=5)
print(f"üîç –ó–∞–ø—Ä–æ—Å: '{query}'")
print(f"–ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}")
for i, doc in enumerate(results, 1):
    print(f"  {i}. {doc.page_content[:50]}...")

print("\n" + "=" * 70)
print("–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï: –†–∞–±–æ—á–∏–π –ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
print("=" * 70)
